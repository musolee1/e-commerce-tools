import asyncio
import random
import pandas as pd
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

# --- AYARLAR ---
TARGET_URL = "https://www.trendyol.com/sr?mid=2457&os=1"
EXCEL_FILENAME = "trendyol_swass_final.xlsx"

# Trendyol'un bot olduÄŸumuzu anlamamasÄ± iÃ§in gerÃ§ek bir bilgisayar kimliÄŸi
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

async def scrape_trendyol():
    async with async_playwright() as p:
        print("ğŸ•µï¸  Gizli tarayÄ±cÄ±, kimlik gizlenerek baÅŸlatÄ±lÄ±yor...")
        
        # TarayÄ±cÄ±yÄ± baÅŸlat (Headless: True -> Pencere aÃ§Ä±lmaz)
        browser = await p.chromium.launch(headless=True)
        
        # Context oluÅŸtururken User-Agent ekliyoruz (Ã‡OK Ã–NEMLÄ°)
        context = await browser.new_context(
            user_agent=USER_AGENT,
            viewport={"width": 1920, "height": 1080}
        )
        
        page = await context.new_page()
        
        print(f"ğŸŒ Siteye gidiliyor: {TARGET_URL}")
        try:
            await page.goto(TARGET_URL, timeout=60000)
            # ÃœrÃ¼n kartlarÄ±nÄ±n yÃ¼klenmesini bekle
            await page.wait_for_selector("div.search-result-content", timeout=15000)
        except Exception as e:
            print("âš ï¸ Sayfa yÃ¼klenirken zaman aÅŸÄ±mÄ± veya hata oldu, devam ediliyor...")

        # --- SCROLL Ä°ÅLEMÄ° ---
        print("â³ TÃ¼m Ã¼rÃ¼nler yÃ¼kleniyor (Scroll yapÄ±lÄ±yor)...")
        last_height = await page.evaluate("document.body.scrollHeight")
        
        while True:
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await page.wait_for_timeout(1500) # YÃ¼klenme iÃ§in bekleme
            
            new_height = await page.evaluate("document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
            
        print("âœ… Sayfa sonuna ulaÅŸÄ±ldÄ±. HTML alÄ±nÄ±yor...")

        # SayfanÄ±n son halinin HTML iÃ§eriÄŸini alÄ±yoruz
        content = await page.content()
        await browser.close()

        # --- BEAUTIFULSOUP Ä°LE PARÃ‡ALAMA ---
        # Playwright yerine BeautifulSoup kullanÄ±yoruz Ã§Ã¼nkÃ¼ daha hata toleranslÄ±dÄ±r.
        soup = BeautifulSoup(content, "html.parser")
        
        # VerdiÄŸin HTML'e gÃ¶re kartlar "a" etiketi ve class="product-card"
        cards = soup.find_all("a", class_="product-card")
        
        print(f"ğŸ“¦ Toplam {len(cards)} adet Ã¼rÃ¼n kartÄ± bulundu. Veriler iÅŸleniyor...")
        
        products_data = []

        for card in cards:
            try:
                # 1. Link
                link = card.get("href")
                if link and not link.startswith("http"):
                    link = "https://www.trendyol.com" + link

                # 2. Ä°sim (Marka + Ad)
                brand = card.find("span", class_="product-brand")
                name = card.find("span", class_="product-name")
                
                brand_text = brand.text.strip() if brand else ""
                name_text = name.text.strip() if name else ""
                full_name = f"{brand_text} {name_text}"

                # 3. Fiyatlar (Senin verdiÄŸin yapÄ±ya gÃ¶re)
                # Ä°ki ihtimal var: Ya "Sepette" kampanyasÄ± vardÄ±r ya da normal indirim.
                
                normal_price = "-"
                discounted_price = "-"
                
                # Ã–nce senin attÄ±ÄŸÄ±n "ty-plus-promotion-price" yapÄ±sÄ±nÄ± kontrol edelim
                promo_div = card.find("div", class_="ty-plus-promotion-price")
                
                if promo_div:
                    # Promosyonlu yapÄ±
                    # ÃœstÃ¼ Ã§izili fiyat
                    strike_tag = promo_div.find("div", class_="strikethrough-price")
                    if strike_tag:
                        normal_price = strike_tag.text.strip()
                    
                    # Ä°ndirimli (Sepette) fiyat
                    price_val_tag = promo_div.find("span", class_="price-value")
                    if price_val_tag:
                        discounted_price = price_val_tag.text.strip()
                
                else:
                    # EÄŸer "Trendyol Plus" Ã¶zel fiyatÄ± yoksa standart fiyat kutusuna bakalÄ±m
                    # Genelde class="prc-box-dscntd" olur
                    price_box = card.find("div", class_="prc-box-dscntd")
                    if price_box:
                        discounted_price = price_box.text.strip()
                        # Bazen burada da Ã¼stÃ¼ Ã§izili fiyat olur
                        box_strike = card.find("div", class_="prc-box-orgnl")
                        if box_strike:
                            normal_price = box_strike.text.strip()

                products_data.append({
                    "ÃœrÃ¼n AdÄ±": full_name,
                    "Normal Fiyat": normal_price,
                    "Ä°ndirimli Fiyat": discounted_price,
                    "Link": link
                })

            except Exception as e:
                print(f"Hata: {e}")
                continue

        return products_data

# --- Ã‡ALIÅTIRMA ---
if __name__ == "__main__":
    data = asyncio.run(scrape_trendyol())
    
    if data:
        df = pd.DataFrame(data)
        df.to_excel(EXCEL_FILENAME, index=False)
        print(f"ğŸ‰ Dosya baÅŸarÄ±yla oluÅŸturuldu: {EXCEL_FILENAME}")
        print(df.head()) # Ä°lk 5 Ã¼rÃ¼nÃ¼ ekrana basar
    else:
        print("âŒ Hala veri Ã§ekilemedi. Trendyol IP adresini geÃ§ici engellemiÅŸ olabilir.")